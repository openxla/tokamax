# proto-file: https://github.com/google-ml-infra/actions/blob/main/benchmarking/proto/benchmark_registry.proto
# proto-message: BenchmarkSuite

benchmarks {
  name: "tokamax_attention_gpu"
  description: "Runs the Tokamax attention benchmark on H100."
  owner: "Tokamax Team"
  update_frequency_policy: QUARTERLY
  workload {
    python_workload {
      script_path: "tokamax/benchmarks/attention.py"
      python_version: "3.11"
    }
  }

  hardware_configs {
    hardware_category: GPU_H100
    topology { num_hosts: 1 num_devices_per_host: 1 }
    workflow_type: [SCHEDULED]
    resource_spec {
      os: LINUX
    }
    pip_optional_dependencies: "cuda"
  }

  hardware_configs {
    hardware_category: GPU_B200
    topology { num_hosts: 1 num_devices_per_host: 1 }
    workflow_type: [SCHEDULED]
    resource_spec {
      os: LINUX
    }
    pip_optional_dependencies: "cuda"
    runtime_flags: "--skip_implementations=None,mosaic"
  }

  metrics {

    name: "attention/default/forward"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }
  metrics {

    name: "attention/default/forward_and_vjp"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }
  metrics {

    name: "attention/triton/forward"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }
  metrics {

    name: "attention/triton/forward_and_vjp"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }
  metrics {

    name: "attention/mosaic/forward"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }
  metrics {

    name: "attention/mosaic/forward_and_vjp"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }
  metrics {

    name: "attention/cudnn/forward"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }
  metrics {

    name: "attention/cudnn/forward_and_vjp"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }
  metrics {

    name: "attention/xla/forward"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }
  metrics {

    name: "attention/xla/forward_and_vjp"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }
}

benchmarks {
  name: "tokamax_triangle_multiplication_gpu"
  description: "Runs the Tokamax triangle_multiplication benchmark on H100 and B200."
  owner: "Tokamax Team"
  update_frequency_policy: QUARTERLY
  workload {
    python_workload {
      script_path: "tokamax/benchmarks/triangle_multiplication.py"
      python_version: "3.11"
    }
  }

  hardware_configs {
    hardware_category: GPU_H100
    topology { num_hosts: 1 num_devices_per_host: 1 }
    workflow_type: [SCHEDULED]
    resource_spec {
      os: LINUX
    }
    pip_optional_dependencies: "cuda"
  }

  hardware_configs {
    hardware_category: GPU_B200
    topology { num_hosts: 1 num_devices_per_host: 1 }
    workflow_type: [SCHEDULED]
    resource_spec {
      os: LINUX
    }
    pip_optional_dependencies: "cuda"
  }

  metrics {
    name: "triangle_multiplication/default/forward"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }
  metrics {
    name: "triangle_multiplication/default/forward_and_vjp"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }
  metrics {
    name: "triangle_multiplication/xla/forward"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }
  metrics {
    name: "triangle_multiplication/xla/forward_and_vjp"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }
}
