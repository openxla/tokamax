# proto-file: https://github.com/google-ml-infra/actions/blob/main/benchmarking/proto/benchmark_registry.proto
# proto-message: BenchmarkSuite

benchmarks {
  name: "tokamax_attention"
  description: "Runs the Tokamax attention benchmark on H100 and B200."
  owner: "Tokamax Team"
  update_frequency_policy: QUARTERLY
  workload {
    action: "./ml_actions/benchmarking/actions/workload_executors/python"
    action_inputs { key: "script_path" value: "tokamax/benchmarks/attention.py" }
    action_inputs { key: "python_version" value: "3.11" }
  }

  environment_configs {
    id: "GPU_H100"
    runner_label: "linux-x86-a3-8g-h100-1gpu"
    container_image: "us-docker.pkg.dev/ml-oss-artifacts-published/ml-public-container/ml-build-cuda13.0-cudnn9.15@sha256:943892a4ab8e9b58a9c7b4297f170d3f28fcb1d479e9835190d49dafdbd2992a"
    workflow_type: [SCHEDULED]
    workload_action_inputs { key: "extras_hw" value: "cuda" }
  }

  environment_configs {
    id: "GPU_B200"
    runner_label: "linux-x86-a4-224-b200-1gpu"
    container_image: "us-docker.pkg.dev/ml-oss-artifacts-published/ml-public-container/ml-build-cuda13.0-cudnn9.15@sha256:943892a4ab8e9b58a9c7b4297f170d3f28fcb1d479e9835190d49dafdbd2992a"
    workflow_type: [SCHEDULED]
    workload_action_inputs { key: "extras_hw" value: "cuda" }
  }

  environment_configs {
    id: "TPUv6e"
    runner_label: "linux-x86-ct6e-44-1tpu"
    container_image: "us-docker.pkg.dev/ml-oss-artifacts-published/ml-public-container/ml-build:latest@sha256:43c523372c4b7f7ce649a1ff204b908727bd338353303c0444af34cb305e5832"
    workflow_type: [SCHEDULED]
    workload_action_inputs { key: "extras_hw" value: "tpu" }
    workload_action_inputs { key: "runtime_flags_hw" value: "--skip_implementations=triton,cudnn" }
  }

  environment_configs {
    id: "TPUv7"
    runner_label: "linux-x86-tpu7x-56-1tpu"
    container_image: "us-docker.pkg.dev/ml-oss-artifacts-published/ml-public-container/ml-build:latest@sha256:43c523372c4b7f7ce649a1ff204b908727bd338353303c0444af34cb305e5832"
    workflow_type: [SCHEDULED]
    workload_action_inputs { key: "extras_hw" value: "tpu" }
    workload_action_inputs { key: "runtime_flags_hw" value: "--skip_implementations=triton,cudnn" }
  }

  metrics {
    name: "attention/basic/default/forward"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }

  metrics {
    name: "attention/basic/default/forward_and_vjp"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }

  metrics {
    name: "attention/basic/triton/forward"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }

  metrics {
    name: "attention/basic/triton/forward_and_vjp"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }

  metrics {
    name: "attention/basic/mosaic/forward"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }

  metrics {
    name: "attention/basic/mosaic/forward_and_vjp"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }

  metrics {
    name: "attention/basic/cudnn/forward"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }

  metrics {
    name: "attention/basic/cudnn/forward_and_vjp"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }

  metrics {
    name: "attention/basic/xla/forward"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }

  metrics {
    name: "attention/basic/xla/forward_and_vjp"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }

  metrics {
    name: "attention/basic/xla_chunked/forward"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }

  metrics {
    name: "attention/basic/xla_chunked/forward_and_vjp"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }

  metrics {
    name: "attention/alphafold/default/forward"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }

  metrics {
    name: "attention/alphafold/default/forward_and_vjp"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }

  metrics {
    name: "attention/alphafold/triton/forward"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }

  metrics {
    name: "attention/alphafold/triton/forward_and_vjp"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }

  metrics {
    name: "attention/alphafold/mosaic/forward"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }

  metrics {
    name: "attention/alphafold/mosaic/forward_and_vjp"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }

  metrics {
    name: "attention/alphafold/cudnn/forward"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }

  metrics {
    name: "attention/alphafold/cudnn/forward_and_vjp"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }

  metrics {
    name: "attention/alphafold/xla/forward"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }

  metrics {
    name: "attention/alphafold/xla/forward_and_vjp"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }

  metrics {
    name: "attention/alphafold/xla_chunked/forward"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }

  metrics {
    name: "attention/alphafold/xla_chunked/forward_and_vjp"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }
}

benchmarks {
  name: "tokamax_triangle_multiplication"
  description: "Runs the Tokamax triangle_multiplication benchmark on H100 and B200."
  owner: "Tokamax Team"
  update_frequency_policy: QUARTERLY
  workload {
    action: "./ml_actions/benchmarking/actions/workload_executors/python"
    action_inputs { key: "script_path" value: "tokamax/benchmarks/triangle_multiplication.py" }
    action_inputs { key: "python_version" value: "3.11" }
  }

  environment_configs {
    id: "GPU_H100"
    runner_label: "linux-x86-a3-8g-h100-1gpu"
    container_image: "us-docker.pkg.dev/ml-oss-artifacts-published/ml-public-container/ml-build-cuda13.0-cudnn9.15@sha256:943892a4ab8e9b58a9c7b4297f170d3f28fcb1d479e9835190d49dafdbd2992a"
    workflow_type: [SCHEDULED]
    workload_action_inputs { key: "extras_hw" value: "cuda" }
  }

  environment_configs {
    id: "GPU_B200"
    runner_label: "linux-x86-a4-224-b200-1gpu"
    container_image: "us-docker.pkg.dev/ml-oss-artifacts-published/ml-public-container/ml-build-cuda13.0-cudnn9.15@sha256:943892a4ab8e9b58a9c7b4297f170d3f28fcb1d479e9835190d49dafdbd2992a"
    workflow_type: [SCHEDULED]
    workload_action_inputs { key: "extras_hw" value: "cuda" }
  }

  environment_configs {
    id: "TPUv6e"
    runner_label: "linux-x86-ct6e-44-1tpu"
    container_image: "us-docker.pkg.dev/ml-oss-artifacts-published/ml-public-container/ml-build:latest@sha256:43c523372c4b7f7ce649a1ff204b908727bd338353303c0444af34cb305e5832"
    workflow_type: [SCHEDULED]
    workload_action_inputs { key: "extras_hw" value: "tpu" }
  }

  environment_configs {
    id: "TPUv7"
    runner_label: "linux-x86-tpu7x-56-1tpu"
    container_image: "us-docker.pkg.dev/ml-oss-artifacts-published/ml-public-container/ml-build:latest@sha256:43c523372c4b7f7ce649a1ff204b908727bd338353303c0444af34cb305e5832"
    workflow_type: [SCHEDULED]
    workload_action_inputs { key: "extras_hw" value: "tpu" }
  }

  metrics {
    name: "triangle_multiplication/default/forward"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }

  metrics {
    name: "triangle_multiplication/default/forward_and_vjp"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }

  metrics {
    name: "triangle_multiplication/xla/forward"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }

  metrics {
    name: "triangle_multiplication/xla/forward_and_vjp"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }
}

benchmarks {
  name: "tokamax_ragged_dot"
  description: "Runs the Tokamax ragged_dot benchmark on H100 and B200."
  owner: "Tokamax Team"
  update_frequency_policy: QUARTERLY
  workload {
    action: "./ml_actions/benchmarking/actions/workload_executors/python"
    action_inputs { key: "script_path" value: "tokamax/benchmarks/ragged_dot.py" }
    action_inputs { key: "python_version" value: "3.11" }
  }

  environment_configs {
    id: "GPU_H100"
    runner_label: "linux-x86-a3-8g-h100-1gpu"
    container_image: "us-docker.pkg.dev/ml-oss-artifacts-published/ml-public-container/ml-build-cuda13.0-cudnn9.15@sha256:943892a4ab8e9b58a9c7b4297f170d3f28fcb1d479e9835190d49dafdbd2992a"
    workflow_type: [SCHEDULED]
    workload_action_inputs { key: "extras_hw" value: "cuda" }
    # Disable 'xla' as this OOM on GPU.
    workload_action_inputs { key: "runtime_flags_hw" value: "--skip_implementations=xla" }
  }

  environment_configs {
    id: "GPU_B200"
    runner_label: "linux-x86-a4-224-b200-1gpu"
    container_image: "us-docker.pkg.dev/ml-oss-artifacts-published/ml-public-container/ml-build-cuda13.0-cudnn9.15@sha256:943892a4ab8e9b58a9c7b4297f170d3f28fcb1d479e9835190d49dafdbd2992a"
    workflow_type: [SCHEDULED]
    workload_action_inputs { key: "extras_hw" value: "cuda" }
    # Disable 'xla' as this OOM on GPU.
    # TODO: enable 'mosaic' and None once the bug is fixed.
    workload_action_inputs { key: "runtime_flags_hw" value: "--skip_implementations=xla,None,mosaic" }
  }

  environment_configs {
    id: "TPUv6e"
    runner_label: "linux-x86-ct6e-44-1tpu"
    container_image: "us-docker.pkg.dev/ml-oss-artifacts-published/ml-public-container/ml-build:latest@sha256:43c523372c4b7f7ce649a1ff204b908727bd338353303c0444af34cb305e5832"
    workflow_type: [SCHEDULED]
    workload_action_inputs { key: "extras_hw" value: "tpu" }
    workload_action_inputs { key: "runtime_flags_hw" value: "--skip_implementations=triton" }
  }

  environment_configs {
    id: "TPUv7"
    runner_label: "linux-x86-tpu7x-56-1tpu"
    container_image: "us-docker.pkg.dev/ml-oss-artifacts-published/ml-public-container/ml-build:latest@sha256:43c523372c4b7f7ce649a1ff204b908727bd338353303c0444af34cb305e5832"
    workflow_type: [SCHEDULED]
    workload_action_inputs { key: "extras_hw" value: "tpu" }
    workload_action_inputs { key: "runtime_flags_hw" value: "--skip_implementations=triton" }
  }

  metrics {
    name: "ragged_dot/default/forward"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }

  metrics {
    name: "ragged_dot/default/forward_and_vjp"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }

  metrics {
    name: "ragged_dot/triton/forward"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }

  metrics {
    name: "ragged_dot/triton/forward_and_vjp"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }

  metrics {
    name: "ragged_dot/mosaic/forward"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }

  metrics {
    name: "ragged_dot/mosaic/forward_and_vjp"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }

  metrics {
    name: "ragged_dot/xla/forward"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }

  metrics {
    name: "ragged_dot/xla/forward_and_vjp"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }

}

