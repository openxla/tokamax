# proto-file: https://github.com/google-ml-infra/actions/blob/main/benchmarking/proto/benchmark_registry.proto
# proto-message: BenchmarkSuite

benchmarks {
  name: "tokamax_attention_gpu"
  description: "Runs the Tokamax attention benchmark on H100 and B200."
  owner: "Tokamax Team"
  update_frequency_policy: QUARTERLY
  workload {
    action: "./ml_actions/benchmarking/actions/workload_executors/python"
    action_inputs { key: "script_path" value: "tokamax/benchmarks/attention.py" }
    action_inputs { key: "python_version" value: "3.11" }
  }

  hardware_configs {
    hardware_category: GPU_H100
    topology { num_hosts: 1 num_devices_per_host: 1 }
    workflow_type: [SCHEDULED]
    resource_spec {
      os: LINUX
    }
    workload_action_inputs { key: "extras_hw" value: "cuda" }
  }

  hardware_configs {
    hardware_category: GPU_B200
    topology { num_hosts: 1 num_devices_per_host: 1 }
    workflow_type: [SCHEDULED]
    resource_spec {
      os: LINUX
    }
    workload_action_inputs { key: "extras_hw" value: "cuda" }
    workload_action_inputs { key: "runtime_flags_hw" value: "--skip_implementations=None,mosaic" }
  }

  metrics {

    name: "attention/default/forward"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }
  metrics {

    name: "attention/default/forward_and_vjp"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }
  metrics {

    name: "attention/triton/forward"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }
  metrics {

    name: "attention/triton/forward_and_vjp"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }
  metrics {

    name: "attention/mosaic/forward"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }
  metrics {

    name: "attention/mosaic/forward_and_vjp"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }
  metrics {

    name: "attention/cudnn/forward"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }
  metrics {

    name: "attention/cudnn/forward_and_vjp"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }
  metrics {

    name: "attention/xla/forward"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }
  metrics {

    name: "attention/xla/forward_and_vjp"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }
}

benchmarks {
  name: "tokamax_triangle_multiplication_gpu"
  description: "Runs the Tokamax triangle_multiplication benchmark on H100 and B200."
  owner: "Tokamax Team"
  update_frequency_policy: QUARTERLY
  workload {
    action: "./ml_actions/benchmarking/actions/workload_executors/python"
    action_inputs { key: "script_path" value: "tokamax/benchmarks/triangle_multiplication.py" }
    action_inputs { key: "python_version" value: "3.11" }
  }

  hardware_configs {
    hardware_category: GPU_H100
    topology { num_hosts: 1 num_devices_per_host: 1 }
    workflow_type: [SCHEDULED]
    resource_spec {
      os: LINUX
    }
    workload_action_inputs { key: "extras_hw" value: "cuda" }
  }

  hardware_configs {
    hardware_category: GPU_B200
    topology { num_hosts: 1 num_devices_per_host: 1 }
    workflow_type: [SCHEDULED]
    resource_spec {
      os: LINUX
    }
    workload_action_inputs { key: "extras_hw" value: "cuda" }
  }

  metrics {
    name: "triangle_multiplication/default/forward"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }
  metrics {
    name: "triangle_multiplication/default/forward_and_vjp"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }
  metrics {
    name: "triangle_multiplication/xla/forward"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }
  metrics {
    name: "triangle_multiplication/xla/forward_and_vjp"
    unit: "ms"
    stats {
      stat: MEDIAN
    }
  }
}
